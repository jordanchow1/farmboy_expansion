{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e20b120-5afd-4f0c-b192-34b4a7f98a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FSAs: 520\n",
      "Stores: 50\n",
      "Non-stores: 470\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, auc,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load datasets\n",
    "ontario_fsa = pd.read_csv('ontario_fsa.csv')\n",
    "farmboy_stores = pd.read_csv('farmboy_stores.csv')\n",
    "\n",
    "# Extract FSAs from store addresses\n",
    "farmboy_stores['FSA'] = farmboy_stores['Address'].str.extract(r'([A-Z]\\d[A-Z])')\n",
    "store_fsas = farmboy_stores['FSA'].dropna().unique()\n",
    "\n",
    "# Create target variable (1 = has store, 0 = no store)\n",
    "ontario_fsa['has_store'] = ontario_fsa['FSA'].isin(store_fsas).astype(int)\n",
    "\n",
    "print(f\"Total FSAs: {len(ontario_fsa)}\")\n",
    "print(f\"Stores: {ontario_fsa['has_store'].sum()}\")\n",
    "print(f\"Non-stores: {(ontario_fsa['has_store'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50025c5a-79e8-4cf2-99b5-74565a5cdc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "FSA                                             0\n",
      "LANDAREA                                        0\n",
      "Bachelor's degree or higher                     3\n",
      "Car, truck or van - as a driver                 3\n",
      "Car, truck or van - as a passenger              3\n",
      "Couple-family households                        3\n",
      "Employed                                        3\n",
      "Employee                                        3\n",
      "Median age of the population                    3\n",
      "Median total income of household in 2020 ($)    4\n",
      "Permanent position                              3\n",
      "Population, 2021                                0\n",
      "Temporary position                              3\n",
      "With children                                   3\n",
      "population_density                              0\n",
      "has_store                                       0\n",
      "dtype: int64\n",
      "\n",
      "Class imbalance ratio: 9.4:1\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(ontario_fsa.isnull().sum())\n",
    "\n",
    "# Check class balance\n",
    "print(f\"\\nClass imbalance ratio: {(ontario_fsa['has_store'] == 0).sum() / ontario_fsa['has_store'].sum():.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e215a9-3b91-4028-b216-1897b0284b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic rates created\n"
     ]
    }
   ],
   "source": [
    "# Convert raw counts to rates (percentages)\n",
    "ontario_fsa['education_rate'] = (\n",
    "    ontario_fsa[\"Bachelor's degree or higher\"] / \n",
    "    ontario_fsa['Population, 2021']\n",
    ") * 100\n",
    "\n",
    "ontario_fsa['employment_rate'] = (\n",
    "    ontario_fsa['Employed'] / \n",
    "    ontario_fsa['Population, 2021']\n",
    ") * 100\n",
    "\n",
    "ontario_fsa['driver_rate'] = (\n",
    "    ontario_fsa['Car, truck or van - as a driver'] / \n",
    "    ontario_fsa['Population, 2021']\n",
    ") * 100\n",
    "\n",
    "ontario_fsa['family_rate'] = (\n",
    "    ontario_fsa['Couple-family households'] / \n",
    "    ontario_fsa['Population, 2021']\n",
    ") * 100\n",
    "\n",
    "ontario_fsa['children_rate'] = (\n",
    "    ontario_fsa['With children'] / \n",
    "    ontario_fsa['Population, 2021']\n",
    ") * 100\n",
    "\n",
    "print(\"Demographic rates created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f085e5d-a7e9-41fa-8158-61f4ee6790fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic features created\n",
      "  Regions: <StringArray>\n",
      "['Other Ontario', 'Ottawa', 'GTA', 'Toronto']\n",
      "Length: 4, dtype: str\n"
     ]
    }
   ],
   "source": [
    "# Assign regions based on FSA prefix\n",
    "def assign_region(fsa):\n",
    "    \"\"\"\n",
    "    M = Toronto\n",
    "    K1, K2 = Ottawa\n",
    "    L4-L9 = GTA\n",
    "    Others = Other Ontario\n",
    "    \"\"\"\n",
    "    if pd.isna(fsa):\n",
    "        return 'Other Ontario'\n",
    "    \n",
    "    first = fsa[0]\n",
    "    second = fsa[1] if len(fsa) > 1 else ''\n",
    "    \n",
    "    if first == 'M':\n",
    "        return 'Toronto'\n",
    "    elif first == 'K' and second in ['1', '2']:\n",
    "        return 'Ottawa'\n",
    "    elif first == 'L' and second in ['4', '5', '6', '7', '9']:\n",
    "        return 'GTA'\n",
    "    else:\n",
    "        return 'Other Ontario'\n",
    "\n",
    "ontario_fsa['region'] = ontario_fsa['FSA'].apply(assign_region)\n",
    "\n",
    "# Create dummy variables (one-hot encoding)\n",
    "# drop_first=True avoids multicollinearity (reference category = GTA)\n",
    "region_dummies = pd.get_dummies(ontario_fsa['region'], prefix='region', drop_first=True)\n",
    "ontario_fsa = pd.concat([ontario_fsa, region_dummies], axis=1)\n",
    "\n",
    "print(\"Geographic features created\")\n",
    "print(f\"  Regions: {ontario_fsa['region'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "484e4d29-748d-4fc6-8bac-27e3063a2c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total features: 15\n",
      "  Demographic: 9\n",
      "  Geographic: 6\n"
     ]
    }
   ],
   "source": [
    "# Select features for model\n",
    "demographic_features = [\n",
    "    'education_rate',\n",
    "    'employment_rate',\n",
    "    'Median age of the population',\n",
    "    'Median total income of household in 2020 ($)',\n",
    "    'population_density',\n",
    "    'Population, 2021',\n",
    "    'driver_rate',\n",
    "    'family_rate',\n",
    "    'children_rate'\n",
    "]\n",
    "\n",
    "geographic_features = [col for col in ontario_fsa.columns if col.startswith('region_')]\n",
    "\n",
    "# Combine all features\n",
    "all_features = demographic_features + geographic_features\n",
    "\n",
    "print(f\"\\nTotal features: {len(all_features)}\")\n",
    "print(f\"  Demographic: {len(demographic_features)}\")\n",
    "print(f\"  Geographic: {len(geographic_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63598652-f0fb-4371-a0de-48fb2ef22d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSAs after removing missing data: 516\n",
      "  Lost 4 FSAs\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values\n",
    "ontario_fsa_clean = ontario_fsa.dropna(subset=all_features + ['has_store'])\n",
    "\n",
    "print(f\"FSAs after removing missing data: {len(ontario_fsa_clean)}\")\n",
    "print(f\"  Lost {len(ontario_fsa) - len(ontario_fsa_clean)} FSAs\")\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = ontario_fsa_clean[all_features]\n",
    "y = ontario_fsa_clean['has_store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87d7c4b-ad70-488e-a32f-8a59c9556dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set: 412 FSAs\n",
      "  Stores: 40\n",
      "  Non-stores: 372\n",
      "\n",
      "Test set: 104 FSAs\n",
      "  Stores: 10\n",
      "  Non-stores: 94\n"
     ]
    }
   ],
   "source": [
    "# Split data: 80% training, 20% testing\n",
    "# stratify=y ensures both sets have same proportion of stores\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,      # 20% for testing\n",
    "    stratify=y          # Maintain class balance\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {len(X_train)} FSAs\")\n",
    "print(f\"  Stores: {y_train.sum()}\")\n",
    "print(f\"  Non-stores: {(y_train == 0).sum()}\")\n",
    "\n",
    "print(f\"\\nTest set: {len(X_test)} FSAs\")\n",
    "print(f\"  Stores: {y_test.sum()}\")\n",
    "print(f\"  Non-stores: {(y_test == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b03949f7-ed68-4f03-8074-956c9add0cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features scaled\n"
     ]
    }
   ],
   "source": [
    "# Standardize features (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeatures scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce949172-50b7-4cb9-afa7-9f7e27502811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression\n",
    "model = LogisticRegression(\n",
    "    class_weight='balanced',    # Handle class imbalance\n",
    "    max_iter=1000,              # Ensure convergence\n",
    "    random_state=42,            # Reproducible results\n",
    "    solver='lbfgs'              # Good for small-medium datasets\n",
    ")\n",
    "\n",
    "# Train (fit) the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "336fbcf7-e72a-43ec-8548-fc8874bf2de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5-Fold Cross-Validation ROC-AUC Scores:\n",
      "  Fold 1: 0.850\n",
      "  Fold 2: 0.820\n",
      "  Fold 3: 0.792\n",
      "  Fold 4: 0.828\n",
      "  Fold 5: 0.799\n",
      "\n",
      "Mean: 0.818\n",
      "Std:  0.021\n",
      "95% CI: [0.776, 0.859]\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    model, \n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    cv=cv,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "print(\"\\n5-Fold Cross-Validation ROC-AUC Scores:\")\n",
    "for fold, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {fold}: {score:.3f}\")\n",
    "\n",
    "print(f\"\\nMean: {cv_scores.mean():.3f}\")\n",
    "print(f\"Std:  {cv_scores.std():.3f}\")\n",
    "print(f\"95% CI: [{cv_scores.mean() - 2*cv_scores.std():.3f}, {cv_scores.mean() + 2*cv_scores.std():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0619f97-b15c-4893-936e-d72ad266f61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions generated\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities (values between 0 and 1)\n",
    "y_train_proba = model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Predict classes (0 or 1, using threshold of 0.5)\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Predictions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b520a474-adc7-4b05-a630-0574945e6059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC-AUC Scores:\n",
      "  Training:   0.853\n",
      "  Test:       0.683\n",
      "  Difference: 0.170\n",
      "  Large gap suggests overfitting\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC-AUC scores\n",
    "roc_auc_train = roc_auc_score(y_train, y_train_proba)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"\\nROC-AUC Scores:\")\n",
    "print(f\"  Training:   {roc_auc_train:.3f}\")\n",
    "print(f\"  Test:       {roc_auc_test:.3f}\")\n",
    "print(f\"  Difference: {abs(roc_auc_train - roc_auc_test):.3f}\")\n",
    "\n",
    "if abs(roc_auc_train - roc_auc_test) > 0.1:\n",
    "    print(\"  Large gap suggests overfitting\")\n",
    "else:\n",
    "    print(\"  Good generalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02615bf3-f6cc-4412-8642-e55b7285ca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted No Store    Predicted Store\n",
      "Actual No Store       76                 18             \n",
      "Actual Store          5                  5              \n",
      "\n",
      "Metrics:\n",
      "  True Positives (correctly predicted stores): 5\n",
      "  False Negatives (missed stores): 5\n",
      "  True Negatives (correctly predicted non-stores): 76\n",
      "  False Positives (incorrectly predicted stores): 18\n",
      "\n",
      "  Precision: 0.217 (When we predict store, we're right 21.7% of time)\n",
      "  Recall: 0.500 (We correctly identify 50.0% of all stores)\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"                 Predicted No Store    Predicted Store\")\n",
    "print(f\"Actual No Store       {cm[0,0]:<18} {cm[0,1]:<15}\")\n",
    "print(f\"Actual Store          {cm[1,0]:<18} {cm[1,1]:<15}\")\n",
    "\n",
    "# Calculate metrics\n",
    "true_neg = cm[0,0]\n",
    "false_pos = cm[0,1]\n",
    "false_neg = cm[1,0]\n",
    "true_pos = cm[1,1]\n",
    "\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  True Positives (correctly predicted stores): {true_pos}\")\n",
    "print(f\"  False Negatives (missed stores): {false_neg}\")\n",
    "print(f\"  True Negatives (correctly predicted non-stores): {true_neg}\")\n",
    "print(f\"  False Positives (incorrectly predicted stores): {false_pos}\")\n",
    "\n",
    "# Precision and Recall\n",
    "if (true_pos + false_pos) > 0:\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    print(f\"\\n  Precision: {precision:.3f} (When we predict store, we're right {precision*100:.1f}% of time)\")\n",
    "\n",
    "if (true_pos + false_neg) > 0:\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    print(f\"  Recall: {recall:.3f} (We correctly identify {recall*100:.1f}% of all stores)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3204027-8526-4a5e-a375-30c320d0d37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All FSAs scored\n",
      "\n",
      "Probability distribution:\n",
      "count    516.000000\n",
      "mean       0.346445\n",
      "std        0.256805\n",
      "min        0.008261\n",
      "25%        0.154103\n",
      "50%        0.245526\n",
      "75%        0.526308\n",
      "max        0.987595\n",
      "Name: store_probability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Scale all FSAs\n",
    "all_fsas_scaled = scaler.transform(ontario_fsa_clean[all_features])\n",
    "\n",
    "# Predict probabilities for all FSAs\n",
    "ontario_fsa_clean['store_probability'] = model.predict_proba(all_fsas_scaled)[:, 1]\n",
    "\n",
    "print(\"All FSAs scored\")\n",
    "print(f\"\\nProbability distribution:\")\n",
    "print(ontario_fsa_clean['store_probability'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8cad550-778f-462f-96df-0edf0191e2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High-potential FSAs (probability > 0.5): 99\n",
      "\n",
      "Top 15 Expansion Opportunities:\n",
      "FSA        region  Population, 2021  education_rate  Median age of the population  store_probability\n",
      "K1P        Ottawa             645.0       58.139535                          32.4           0.987595\n",
      "K1S        Ottawa           31257.0       40.087021                          39.2           0.980855\n",
      "K1Y        Ottawa           20712.0       41.473542                          40.0           0.980180\n",
      "K1R        Ottawa           20343.0       40.013764                          36.0           0.972960\n",
      "K1M        Ottawa            6764.0       37.403903                          50.0           0.926243\n",
      "K1V        Ottawa           57157.0       23.234250                          38.0           0.916323\n",
      "K2A        Ottawa           17156.0       31.796456                          47.2           0.913998\n",
      "L5M           GTA          106468.0       31.910997                          39.6           0.903521\n",
      "L6M           GTA           72547.0       34.363930                          39.6           0.898970\n",
      "K2M        Ottawa           28708.0       29.416887                          38.4           0.897460\n",
      "K2K        Ottawa           24922.0       29.050638                          45.2           0.892560\n",
      "M5G       Toronto            9751.0       53.430417                          30.8           0.886781\n",
      "K1C        Ottawa           37235.0       22.814556                          46.0           0.883827\n",
      "K0A Other Ontario          111626.0       14.777023                          44.0           0.883285\n",
      "L9T           GTA          110956.0       26.100436                          36.4           0.882844\n",
      "\n",
      "Aggregate Metrics:\n",
      "  Total population: 3,847,427\n",
      "  Average probability: 0.715\n",
      "  Estimated revenue: $5771M - $9619M\n"
     ]
    }
   ],
   "source": [
    "# Find FSAs without stores but high probability\n",
    "high_potential = ontario_fsa_clean[\n",
    "    (ontario_fsa_clean['has_store'] == 0) &  # No store currently\n",
    "    (ontario_fsa_clean['store_probability'] > 0.5)  # High probability\n",
    "].copy()\n",
    "\n",
    "# Sort by probability\n",
    "high_potential = high_potential.sort_values('store_probability', ascending=False)\n",
    "\n",
    "print(f\"\\nHigh-potential FSAs (probability > 0.5): {len(high_potential)}\")\n",
    "\n",
    "if len(high_potential) > 0:\n",
    "    print(\"\\nTop 15 Expansion Opportunities:\")\n",
    "    display_cols = [\n",
    "        'FSA', 'region', 'Population, 2021', 'education_rate',\n",
    "        'Median age of the population', 'store_probability'\n",
    "    ]\n",
    "    print(high_potential[display_cols].head(15).to_string(index=False))\n",
    "    \n",
    "    # Business metrics\n",
    "    total_pop = high_potential['Population, 2021'].sum()\n",
    "    avg_prob = high_potential['store_probability'].mean()\n",
    "    \n",
    "    print(f\"\\nAggregate Metrics:\")\n",
    "    print(f\"  Total population: {total_pop:,.0f}\")\n",
    "    print(f\"  Average probability: {avg_prob:.3f}\")\n",
    "    print(f\"  Estimated revenue: ${total_pop * 1500 / 1_000_000:.0f}M - ${total_pop * 2500 / 1_000_000:.0f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1223c7c-ad39-4488-89f8-770c3aebcdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FSAs by Priority (excluding current stores):\n",
      "           FSA  Population, 2021\n",
      "priority                        \n",
      "LOW        288         6230260.0\n",
      "MEDIUM      79         2386481.0\n",
      "HIGH        45         1769780.0\n",
      "VERY HIGH   54         2077647.0\n"
     ]
    }
   ],
   "source": [
    "# Categorize FSAs by probability\n",
    "ontario_fsa_clean['priority'] = pd.cut(\n",
    "    ontario_fsa_clean['store_probability'],\n",
    "    bins=[0, 0.3, 0.5, 0.7, 1.0],\n",
    "    labels=['LOW', 'MEDIUM', 'HIGH', 'VERY HIGH']\n",
    ")\n",
    "\n",
    "# Summary by priority\n",
    "print(\"\\nFSAs by Priority (excluding current stores):\")\n",
    "priority_summary = ontario_fsa_clean[\n",
    "    ontario_fsa_clean['has_store'] == 0\n",
    "].groupby('priority').agg({\n",
    "    'FSA': 'count',\n",
    "    'Population, 2021': 'sum'\n",
    "})\n",
    "\n",
    "print(priority_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63cc4a42-1d7d-4715-b9a8-dba4e0d25742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: fsa_scores_logistic_regression.csv\n",
      "Saved: high_potential_fsas.csv\n",
      "Saved: logistic_model.pkl and scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save scored FSAs\n",
    "ontario_fsa_clean.to_csv('fsa_scores_logistic_regression.csv', index=False)\n",
    "print(\"\\nSaved: fsa_scores_logistic_regression.csv\")\n",
    "\n",
    "# Save high-potential FSAs\n",
    "if len(high_potential) > 0:\n",
    "    high_potential.to_csv('high_potential_fsas.csv', index=False)\n",
    "    print(\"Saved: high_potential_fsas.csv\")\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "with open('logistic_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Saved: logistic_model.pkl and scaler.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
